{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFhSljeOCnRw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multivariate Time Series Prediction Using Transformers Architecture\n",
    "\n",
    "The following Notebook shows the coding part of my Bachelor Thesis for the Information and Communication Systems and Services bachelor degree in the University of Applied Science Technikum Wien.\n",
    "\n",
    "Author: Sergio Tallo Torres\n",
    "Date: May 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0esqvQHT2922",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First: load imports needed for the project and project preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU = NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from platform import python_version\n",
    "\n",
    "import utils_bsc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Device: GPU =', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Device: CPU')\n",
    "\n",
    "saved_results = 'training_results'\n",
    "\n",
    "# Check whether the directory where the results files must be saved exists or not\n",
    "if not os.path.exists(saved_results):\n",
    "  # Create a new directory because it does not exist\n",
    "  os.makedirs(saved_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions of packages:\n",
      "Python: 3.8.13\n",
      "Pandas: 1.4.1\n",
      "Numpy: 1.22.3\n",
      "PyTorch: 1.11.0+cu113\n",
      "Sklearn: 1.0.2\n",
      "seaborn: 0.11.2\n",
      "scipy: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print('versions of packages:')\n",
    "print(f'Python: {python_version()}')\n",
    "print(f'Pandas: {pd.__version__}')\n",
    "print(f'Numpy: {np.__version__}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Sklearn: {sklearn.__version__}')\n",
    "print(f'seaborn: {sns.__version__}')\n",
    "print(f'scipy: {scipy.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is necessary to use this notebook in google colab\n",
    "# If you are running this notebook in colab, please change colab to True\n",
    "\n",
    "colab = False\n",
    "\n",
    "if colab is True:\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    if cwd != \"/content/Bsc_Thesis\":\n",
    "        ! git clone https://github.com/SergioTallo/Bsc_Thesis.git\n",
    "        % cd Bsc_Thesis\n",
    "\n",
    "    print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we should create a dataset with all the data stored in the .csv file\n",
    "\n",
    "Description of the data:\n",
    "\n",
    "*   time: Timestamp (YYYY-MM-DD HH:MM:SS)\n",
    "*   PLN1: Power in the phase 1 (W)\n",
    "*   PLN2: Power in the phase 2 (W)\n",
    "*   PLN3: Power in the phase 3 (W)\n",
    "*   ULL1: Current Voltage between 2 phases (V)\n",
    "*   ULL2: Current Voltage between 2 phases (V)\n",
    "*   ULL3: Current Voltage between 2 phases (V)\n",
    "*   COS_PHI1: Phase shift (Cos)\n",
    "*   COS_PHI2: Phase shift (Cos)\n",
    "*   COS_PHI3: Phase shift (Cos)\n",
    "*   FREQ: Electricity Frequency (Hz)\n",
    "*   RC_DC: Fault currents\n",
    "*   RC_AC: Fault currents\n",
    "*   RC_50Hz: Fault currents\n",
    "*   RC_150Hz: Fault currents\n",
    "*   RC_<100Hz: Fault currents\n",
    "*   RC_100Hz-1kHz: Fault currents\n",
    "*   RC_>10kHz: Fault currents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PLN1</th>\n",
       "      <th>PLN2</th>\n",
       "      <th>PLN3</th>\n",
       "      <th>ULL1</th>\n",
       "      <th>ULL2</th>\n",
       "      <th>ULL3</th>\n",
       "      <th>COS_PHI1</th>\n",
       "      <th>COS_PHI2</th>\n",
       "      <th>COS_PHI3</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>RC_DC</th>\n",
       "      <th>RC_AC</th>\n",
       "      <th>RC_50Hz</th>\n",
       "      <th>RC_150Hz</th>\n",
       "      <th>RC_&lt;100Hz</th>\n",
       "      <th>RC_100Hz-1kHz</th>\n",
       "      <th>RC_&gt;1kHz</th>\n",
       "      <th>RC_&gt;10kHz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>1141.0819</td>\n",
       "      <td>519.5034</td>\n",
       "      <td>482.9381</td>\n",
       "      <td>398.8613</td>\n",
       "      <td>400.1982</td>\n",
       "      <td>395.6010</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>49.9927</td>\n",
       "      <td>4.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01 00:01:00</td>\n",
       "      <td>1145.1162</td>\n",
       "      <td>519.1807</td>\n",
       "      <td>491.4436</td>\n",
       "      <td>398.6934</td>\n",
       "      <td>400.1579</td>\n",
       "      <td>395.5431</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>49.9779</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01 00:02:00</td>\n",
       "      <td>1140.9558</td>\n",
       "      <td>743.3837</td>\n",
       "      <td>484.9942</td>\n",
       "      <td>398.4367</td>\n",
       "      <td>400.1205</td>\n",
       "      <td>395.5259</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>49.9782</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01 00:03:00</td>\n",
       "      <td>1151.9409</td>\n",
       "      <td>741.4836</td>\n",
       "      <td>487.4224</td>\n",
       "      <td>398.9800</td>\n",
       "      <td>400.4375</td>\n",
       "      <td>395.8621</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>49.9850</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01 00:04:00</td>\n",
       "      <td>1142.1594</td>\n",
       "      <td>741.9858</td>\n",
       "      <td>486.7629</td>\n",
       "      <td>398.7133</td>\n",
       "      <td>400.3145</td>\n",
       "      <td>395.6446</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>0.9291</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>49.9856</td>\n",
       "      <td>4.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time       PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
       "0  2020-06-01 00:00:00  1141.0819  519.5034  482.9381  398.8613  400.1982   \n",
       "1  2020-06-01 00:01:00  1145.1162  519.1807  491.4436  398.6934  400.1579   \n",
       "2  2020-06-01 00:02:00  1140.9558  743.3837  484.9942  398.4367  400.1205   \n",
       "3  2020-06-01 00:03:00  1151.9409  741.4836  487.4224  398.9800  400.4375   \n",
       "4  2020-06-01 00:04:00  1142.1594  741.9858  486.7629  398.7133  400.3145   \n",
       "\n",
       "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3     FREQ  RC_DC  RC_AC  RC_50Hz  \\\n",
       "0  395.6010    0.8091    0.6864    0.4875  49.9927    4.0   91.0     10.0   \n",
       "1  395.5431    0.8080    0.6903    0.4904  49.9779    5.0   64.0      7.0   \n",
       "2  395.5259    0.8113    0.9274    0.4806  49.9782    4.0   64.0      7.0   \n",
       "3  395.8621    0.8249    0.9123    0.4778  49.9850    5.0   66.0      8.0   \n",
       "4  395.6446    0.8081    0.9291    0.4552  49.9856    4.0   85.0     11.0   \n",
       "\n",
       "   RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
       "0      39.0       36.0           86.0      82.0        7.0  \n",
       "1      27.0       25.0           60.0      55.0        2.0  \n",
       "2      27.0       25.0           60.0      55.0        2.0  \n",
       "3      28.0       25.0           61.0      57.0        2.0  \n",
       "4      45.0       41.0           75.0      68.0        6.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data_factory.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have the dataset, we should prepare it. Finding the missing or the NaN values and replace them with suitable values (in this case we use the value of the previous elemnt in the sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values before cleaning: 2546\n",
      "Number of rows with NaN values after cleaning: 0\n",
      "Total number of samples: 63360\n",
      "Number of features: 19\n"
     ]
    }
   ],
   "source": [
    "# Replace all mising values with NaN\n",
    "dataset = dataset.replace(' ', np.nan)\n",
    "# Search for all the rows with NaN values\n",
    "nan_values = dataset[dataset.isna().any(axis=1)]\n",
    "# Print the shape to know how many are there\n",
    "print(f'Number of rows with NaN values before cleaning: {nan_values.shape[0]}') \n",
    "\n",
    "# Fill all NaN values with the previous row value\n",
    "dataset_clean = dataset.fillna(method='ffill')\n",
    "\n",
    "# Check that there isn't any NaN values\n",
    "nan_values = dataset_clean[dataset_clean.isna().any(axis=1)]\n",
    "# Print the shape to know how many are there\n",
    "print(f'Number of rows with NaN values after cleaning: {nan_values.shape[0]}') \n",
    "\n",
    "#Total number of samples\n",
    "print(f'Total number of samples: {dataset_clean.shape[0]}')\n",
    "print(f'Number of features: {dataset_clean.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Distribution of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we look at the distribution of the different features of the data over different time intervals.\n",
    "First we take a look of the min and max values, mean and median value and the standard deviation of every feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_data = False\n",
    "print_graphs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if print_data is True:\n",
    "  for column in dataset_clean.columns:\n",
    "    if column == 'time':\n",
    "      print(column)\n",
    "      print('Min value: ', dataset_clean[column].min())\n",
    "      print('Max value: ', dataset_clean[column].max())\n",
    "      print('')\n",
    "    else:\n",
    "      print(column)\n",
    "      print('Min value: ', dataset_clean[column].min())\n",
    "      print('Max value: ', dataset_clean[column].max())\n",
    "      print('Mean value: ', dataset_clean[column].mean())\n",
    "      print('Median value: ', dataset_clean[column].median())\n",
    "      print('Standard deviation: ', dataset_clean[column].std())\n",
    "      print('')\n",
    "print_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_graphs = False\n",
    "if print_graphs is True:\n",
    "\n",
    "  for i, column in enumerate(dataset_clean.columns):\n",
    "    if i > 0 & i<3:\n",
    "      # Feature in a weekly interval\n",
    "      utils_bsc.week_plot(dataset_clean, i, column)\n",
    "      # Feature in a daily interval (only the values of weekdays between 4:00 and 19:30)\n",
    "      utils_bsc.daily_plot(dataset_clean, i, column)\n",
    "print_graphs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_graphs = False\n",
    "# 我们打印一些图表来显示每个特征的密度分布\n",
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_clean.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_clean, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After looking to the different data graphs i notice there two very different \"time slots\" when the data differs. One is Weekdays between 4:00 and 19:30. The other is Weekdays bewteen 19:30 and 4:00 and Weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekdays dataset size: 29792\n",
      "Weekend dataset size: 33568\n"
     ]
    }
   ],
   "source": [
    "# 我们创建了两个额外的数据集，一个包含工作日 4:00 到 18:30 之间，一个包含其余数据集。\n",
    "dataset_clean_time = pd.to_datetime(dataset_clean['time'])\n",
    "\n",
    "day_mask = dataset_clean_time.dt.day_name()\n",
    "\n",
    "time_mask = (dataset_clean_time.dt.hour >= 4) & ((dataset_clean_time.dt.hour < 19) | ((dataset_clean_time.dt.hour == 19) & (dataset_clean_time.dt.minute <= 30))) & ((day_mask == ('Monday')) | (day_mask == ('Tuesday')) | (day_mask == ('Wednesday')) | (day_mask == ('Thursday')) | (day_mask == ('Friday')))\n",
    "\n",
    "dataset_weekdays = dataset_clean[time_mask]\n",
    "\n",
    "for i in range(len(time_mask)):\n",
    "  if time_mask[i] == False:\n",
    "    time_mask[i] = True\n",
    "  elif time_mask[i] == True:\n",
    "    time_mask[i] = False\n",
    "\n",
    "dataset_weekend = dataset_clean[time_mask]\n",
    "\n",
    "print(f'Weekdays dataset size: {len(dataset_weekdays)}')\n",
    "print(f'Weekend dataset size: {len(dataset_weekend)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_weekdays.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_weekdays, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_weekend.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_weekend, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this time we have three different datasets:\n",
    "\n",
    "* dataset_clean (Whole dataset)\n",
    "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
    "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset normalisation\n",
    "\n",
    "The scale of the data of the different features is very different. Its better to have all of the features in the same scale. Therefore we perform a data normalisation. We choose to do a mean/stddev normalisation. We substract from every value the mean value of the feature and divide the result value by the std dev of this specific feature to have feature values with mean 0 and stddev of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 410.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#在整个数据集中执行数据规范化。如果需要，我们可以打印数据的分布。\n",
    "dataset_norm = utils_bsc.normalize_mean_std_dataset(dataset_clean)\n",
    "\n",
    "print_graphs = False\n",
    "\n",
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_norm.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_norm, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 669.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
    "dataset_weekdays_norm = utils_bsc.normalize_mean_std_dataset(dataset_weekdays)\n",
    "\n",
    "print_graphs = False\n",
    "\n",
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_weekdays_norm.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_weekdays_norm, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 511.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the data normalisation in the weekdays dataset. We can print the distribution of the data if we want.\n",
    "dataset_weekend_norm = utils_bsc.normalize_mean_std_dataset(dataset_weekend)\n",
    "\n",
    "print_graphs = False\n",
    "\n",
    "if print_graphs is True:\n",
    "  for column in tqdm(dataset_weekend_norm.columns):\n",
    "    if column != 'time':\n",
    "      sns.displot(dataset_weekend_norm, x=column, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PLN1</th>\n",
       "      <th>PLN2</th>\n",
       "      <th>PLN3</th>\n",
       "      <th>ULL1</th>\n",
       "      <th>ULL2</th>\n",
       "      <th>ULL3</th>\n",
       "      <th>COS_PHI1</th>\n",
       "      <th>COS_PHI2</th>\n",
       "      <th>COS_PHI3</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>RC_DC</th>\n",
       "      <th>RC_AC</th>\n",
       "      <th>RC_50Hz</th>\n",
       "      <th>RC_150Hz</th>\n",
       "      <th>RC_&lt;100Hz</th>\n",
       "      <th>RC_100Hz-1kHz</th>\n",
       "      <th>RC_&gt;1kHz</th>\n",
       "      <th>RC_&gt;10kHz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>-1.075593</td>\n",
       "      <td>-1.045021</td>\n",
       "      <td>-1.051232</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>-0.098312</td>\n",
       "      <td>-0.618908</td>\n",
       "      <td>-1.868350</td>\n",
       "      <td>-1.835847</td>\n",
       "      <td>-1.500292</td>\n",
       "      <td>-0.345935</td>\n",
       "      <td>-0.817380</td>\n",
       "      <td>0.632551</td>\n",
       "      <td>1.075812</td>\n",
       "      <td>0.995360</td>\n",
       "      <td>1.143832</td>\n",
       "      <td>0.694697</td>\n",
       "      <td>0.747095</td>\n",
       "      <td>2.141318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01 00:01:00</td>\n",
       "      <td>-1.074875</td>\n",
       "      <td>-1.045103</td>\n",
       "      <td>-1.048747</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>-0.107515</td>\n",
       "      <td>-0.632738</td>\n",
       "      <td>-1.884005</td>\n",
       "      <td>-1.803753</td>\n",
       "      <td>-1.486828</td>\n",
       "      <td>-1.139728</td>\n",
       "      <td>0.678985</td>\n",
       "      <td>-0.849829</td>\n",
       "      <td>-0.918340</td>\n",
       "      <td>-0.792166</td>\n",
       "      <td>-0.630653</td>\n",
       "      <td>-0.822036</td>\n",
       "      <td>-0.777047</td>\n",
       "      <td>-1.175568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01 00:02:00</td>\n",
       "      <td>-1.075615</td>\n",
       "      <td>-0.988316</td>\n",
       "      <td>-1.050631</td>\n",
       "      <td>-0.028760</td>\n",
       "      <td>-0.116055</td>\n",
       "      <td>-0.636846</td>\n",
       "      <td>-1.837041</td>\n",
       "      <td>0.147415</td>\n",
       "      <td>-1.532327</td>\n",
       "      <td>-1.123638</td>\n",
       "      <td>-0.817380</td>\n",
       "      <td>-0.849829</td>\n",
       "      <td>-0.918340</td>\n",
       "      <td>-0.792166</td>\n",
       "      <td>-0.630653</td>\n",
       "      <td>-0.822036</td>\n",
       "      <td>-0.777047</td>\n",
       "      <td>-1.175568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01 00:03:00</td>\n",
       "      <td>-1.073661</td>\n",
       "      <td>-0.988798</td>\n",
       "      <td>-1.049922</td>\n",
       "      <td>0.089264</td>\n",
       "      <td>-0.043667</td>\n",
       "      <td>-0.556540</td>\n",
       "      <td>-1.643493</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>-1.545327</td>\n",
       "      <td>-0.758922</td>\n",
       "      <td>0.678985</td>\n",
       "      <td>-0.740023</td>\n",
       "      <td>-0.253623</td>\n",
       "      <td>-0.643206</td>\n",
       "      <td>-0.630653</td>\n",
       "      <td>-0.763700</td>\n",
       "      <td>-0.664147</td>\n",
       "      <td>-1.175568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01 00:04:00</td>\n",
       "      <td>-1.075401</td>\n",
       "      <td>-0.988670</td>\n",
       "      <td>-1.050114</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>-0.071754</td>\n",
       "      <td>-0.608493</td>\n",
       "      <td>-1.882582</td>\n",
       "      <td>0.161405</td>\n",
       "      <td>-1.650254</td>\n",
       "      <td>-0.726741</td>\n",
       "      <td>-0.817380</td>\n",
       "      <td>0.303134</td>\n",
       "      <td>1.740530</td>\n",
       "      <td>1.889123</td>\n",
       "      <td>1.950416</td>\n",
       "      <td>0.053002</td>\n",
       "      <td>-0.043201</td>\n",
       "      <td>1.477941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
       "0  2020-06-01 00:00:00 -1.075593 -1.045021 -1.051232  0.063478 -0.098312   \n",
       "1  2020-06-01 00:01:00 -1.074875 -1.045103 -1.048747  0.027004 -0.107515   \n",
       "2  2020-06-01 00:02:00 -1.075615 -0.988316 -1.050631 -0.028760 -0.116055   \n",
       "3  2020-06-01 00:03:00 -1.073661 -0.988798 -1.049922  0.089264 -0.043667   \n",
       "4  2020-06-01 00:04:00 -1.075401 -0.988670 -1.050114  0.031327 -0.071754   \n",
       "\n",
       "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
       "0 -0.618908 -1.868350 -1.835847 -1.500292 -0.345935 -0.817380  0.632551   \n",
       "1 -0.632738 -1.884005 -1.803753 -1.486828 -1.139728  0.678985 -0.849829   \n",
       "2 -0.636846 -1.837041  0.147415 -1.532327 -1.123638 -0.817380 -0.849829   \n",
       "3 -0.556540 -1.643493  0.023152 -1.545327 -0.758922  0.678985 -0.740023   \n",
       "4 -0.608493 -1.882582  0.161405 -1.650254 -0.726741 -0.817380  0.303134   \n",
       "\n",
       "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
       "0  1.075812  0.995360   1.143832       0.694697  0.747095   2.141318  \n",
       "1 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
       "2 -0.918340 -0.792166  -0.630653      -0.822036 -0.777047  -1.175568  \n",
       "3 -0.253623 -0.643206  -0.630653      -0.763700 -0.664147  -1.175568  \n",
       "4  1.740530  1.889123   1.950416       0.053002 -0.043201   1.477941  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PLN1</th>\n",
       "      <th>PLN2</th>\n",
       "      <th>PLN3</th>\n",
       "      <th>ULL1</th>\n",
       "      <th>ULL2</th>\n",
       "      <th>ULL3</th>\n",
       "      <th>COS_PHI1</th>\n",
       "      <th>COS_PHI2</th>\n",
       "      <th>COS_PHI3</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>RC_DC</th>\n",
       "      <th>RC_AC</th>\n",
       "      <th>RC_50Hz</th>\n",
       "      <th>RC_150Hz</th>\n",
       "      <th>RC_&lt;100Hz</th>\n",
       "      <th>RC_100Hz-1kHz</th>\n",
       "      <th>RC_&gt;1kHz</th>\n",
       "      <th>RC_&gt;10kHz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2020-06-01 04:00:00</td>\n",
       "      <td>-3.844526</td>\n",
       "      <td>-2.815111</td>\n",
       "      <td>-3.811858</td>\n",
       "      <td>1.679619</td>\n",
       "      <td>1.570822</td>\n",
       "      <td>1.782563</td>\n",
       "      <td>-1.458455</td>\n",
       "      <td>-0.043591</td>\n",
       "      <td>-11.695581</td>\n",
       "      <td>-0.570289</td>\n",
       "      <td>-0.884008</td>\n",
       "      <td>-3.224201</td>\n",
       "      <td>-1.568103</td>\n",
       "      <td>-1.701045</td>\n",
       "      <td>-1.466370</td>\n",
       "      <td>-3.271799</td>\n",
       "      <td>-2.865462</td>\n",
       "      <td>-1.695805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2020-06-01 04:01:00</td>\n",
       "      <td>-3.846186</td>\n",
       "      <td>-3.787824</td>\n",
       "      <td>-3.823188</td>\n",
       "      <td>1.763631</td>\n",
       "      <td>1.696076</td>\n",
       "      <td>1.843617</td>\n",
       "      <td>-1.467086</td>\n",
       "      <td>-2.835547</td>\n",
       "      <td>-11.782866</td>\n",
       "      <td>0.903443</td>\n",
       "      <td>2.133621</td>\n",
       "      <td>-3.224201</td>\n",
       "      <td>-1.568103</td>\n",
       "      <td>-1.701045</td>\n",
       "      <td>-1.466370</td>\n",
       "      <td>-3.357651</td>\n",
       "      <td>-2.939190</td>\n",
       "      <td>-1.695805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2020-06-01 04:02:00</td>\n",
       "      <td>-3.839272</td>\n",
       "      <td>-1.875102</td>\n",
       "      <td>-2.712874</td>\n",
       "      <td>1.852445</td>\n",
       "      <td>1.730759</td>\n",
       "      <td>1.917486</td>\n",
       "      <td>-1.557711</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>-1.543490</td>\n",
       "      <td>0.445873</td>\n",
       "      <td>0.624807</td>\n",
       "      <td>-1.273229</td>\n",
       "      <td>-0.765503</td>\n",
       "      <td>-1.118658</td>\n",
       "      <td>-0.885575</td>\n",
       "      <td>-1.211362</td>\n",
       "      <td>-0.948518</td>\n",
       "      <td>-0.928865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-06-01 04:03:00</td>\n",
       "      <td>-3.842709</td>\n",
       "      <td>-3.088604</td>\n",
       "      <td>-3.827000</td>\n",
       "      <td>1.832063</td>\n",
       "      <td>1.744944</td>\n",
       "      <td>1.905749</td>\n",
       "      <td>-1.475716</td>\n",
       "      <td>-0.716154</td>\n",
       "      <td>-12.237347</td>\n",
       "      <td>-0.219683</td>\n",
       "      <td>0.624807</td>\n",
       "      <td>-1.923553</td>\n",
       "      <td>-1.568103</td>\n",
       "      <td>-1.312787</td>\n",
       "      <td>-1.272772</td>\n",
       "      <td>-2.069878</td>\n",
       "      <td>-1.538347</td>\n",
       "      <td>-0.928865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-06-01 04:04:00</td>\n",
       "      <td>-3.844287</td>\n",
       "      <td>-2.842539</td>\n",
       "      <td>-3.450520</td>\n",
       "      <td>1.753998</td>\n",
       "      <td>1.623568</td>\n",
       "      <td>1.808403</td>\n",
       "      <td>-1.527502</td>\n",
       "      <td>-0.430725</td>\n",
       "      <td>-5.973931</td>\n",
       "      <td>-0.611886</td>\n",
       "      <td>-0.884008</td>\n",
       "      <td>-1.842262</td>\n",
       "      <td>-0.765503</td>\n",
       "      <td>-1.312787</td>\n",
       "      <td>-1.272772</td>\n",
       "      <td>-2.069878</td>\n",
       "      <td>-1.464618</td>\n",
       "      <td>-0.928865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
       "240  2020-06-01 04:00:00 -3.844526 -2.815111 -3.811858  1.679619  1.570822   \n",
       "241  2020-06-01 04:01:00 -3.846186 -3.787824 -3.823188  1.763631  1.696076   \n",
       "242  2020-06-01 04:02:00 -3.839272 -1.875102 -2.712874  1.852445  1.730759   \n",
       "243  2020-06-01 04:03:00 -3.842709 -3.088604 -3.827000  1.832063  1.744944   \n",
       "244  2020-06-01 04:04:00 -3.844287 -2.842539 -3.450520  1.753998  1.623568   \n",
       "\n",
       "         ULL3  COS_PHI1  COS_PHI2   COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
       "240  1.782563 -1.458455 -0.043591 -11.695581 -0.570289 -0.884008 -3.224201   \n",
       "241  1.843617 -1.467086 -2.835547 -11.782866  0.903443  2.133621 -3.224201   \n",
       "242  1.917486 -1.557711  0.058113  -1.543490  0.445873  0.624807 -1.273229   \n",
       "243  1.905749 -1.475716 -0.716154 -12.237347 -0.219683  0.624807 -1.923553   \n",
       "244  1.808403 -1.527502 -0.430725  -5.973931 -0.611886 -0.884008 -1.842262   \n",
       "\n",
       "      RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
       "240 -1.568103 -1.701045  -1.466370      -3.271799 -2.865462  -1.695805  \n",
       "241 -1.568103 -1.701045  -1.466370      -3.357651 -2.939190  -1.695805  \n",
       "242 -0.765503 -1.118658  -0.885575      -1.211362 -0.948518  -0.928865  \n",
       "243 -1.568103 -1.312787  -1.272772      -2.069878 -1.538347  -0.928865  \n",
       "244 -0.765503 -1.312787  -1.272772      -2.069878 -1.464618  -0.928865  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_weekdays_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PLN1</th>\n",
       "      <th>PLN2</th>\n",
       "      <th>PLN3</th>\n",
       "      <th>ULL1</th>\n",
       "      <th>ULL2</th>\n",
       "      <th>ULL3</th>\n",
       "      <th>COS_PHI1</th>\n",
       "      <th>COS_PHI2</th>\n",
       "      <th>COS_PHI3</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>RC_DC</th>\n",
       "      <th>RC_AC</th>\n",
       "      <th>RC_50Hz</th>\n",
       "      <th>RC_150Hz</th>\n",
       "      <th>RC_&lt;100Hz</th>\n",
       "      <th>RC_100Hz-1kHz</th>\n",
       "      <th>RC_&gt;1kHz</th>\n",
       "      <th>RC_&gt;10kHz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>-0.520051</td>\n",
       "      <td>-0.469417</td>\n",
       "      <td>-0.491179</td>\n",
       "      <td>-0.852017</td>\n",
       "      <td>-1.003068</td>\n",
       "      <td>-1.783292</td>\n",
       "      <td>-1.338808</td>\n",
       "      <td>-1.189834</td>\n",
       "      <td>-0.885658</td>\n",
       "      <td>-0.479759</td>\n",
       "      <td>-0.761410</td>\n",
       "      <td>1.276387</td>\n",
       "      <td>1.388355</td>\n",
       "      <td>1.509262</td>\n",
       "      <td>1.555410</td>\n",
       "      <td>1.427389</td>\n",
       "      <td>1.381491</td>\n",
       "      <td>2.307679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01 00:01:00</td>\n",
       "      <td>-0.518390</td>\n",
       "      <td>-0.469592</td>\n",
       "      <td>-0.485656</td>\n",
       "      <td>-0.905465</td>\n",
       "      <td>-1.016009</td>\n",
       "      <td>-1.803094</td>\n",
       "      <td>-1.356629</td>\n",
       "      <td>-1.159350</td>\n",
       "      <td>-0.870606</td>\n",
       "      <td>-1.233069</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>-0.330467</td>\n",
       "      <td>-0.570467</td>\n",
       "      <td>-0.350376</td>\n",
       "      <td>-0.254028</td>\n",
       "      <td>-0.283821</td>\n",
       "      <td>-0.298828</td>\n",
       "      <td>-0.881879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01 00:02:00</td>\n",
       "      <td>-0.520102</td>\n",
       "      <td>-0.348132</td>\n",
       "      <td>-0.489844</td>\n",
       "      <td>-0.987181</td>\n",
       "      <td>-1.028018</td>\n",
       "      <td>-1.808977</td>\n",
       "      <td>-1.303165</td>\n",
       "      <td>0.693881</td>\n",
       "      <td>-0.921471</td>\n",
       "      <td>-1.217799</td>\n",
       "      <td>-0.761410</td>\n",
       "      <td>-0.330467</td>\n",
       "      <td>-0.570467</td>\n",
       "      <td>-0.350376</td>\n",
       "      <td>-0.254028</td>\n",
       "      <td>-0.283821</td>\n",
       "      <td>-0.298828</td>\n",
       "      <td>-0.881879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01 00:03:00</td>\n",
       "      <td>-0.515582</td>\n",
       "      <td>-0.349161</td>\n",
       "      <td>-0.488267</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>-0.926227</td>\n",
       "      <td>-1.693993</td>\n",
       "      <td>-1.082826</td>\n",
       "      <td>0.575856</td>\n",
       "      <td>-0.936003</td>\n",
       "      <td>-0.871684</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>-0.211441</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>-0.195407</td>\n",
       "      <td>-0.254028</td>\n",
       "      <td>-0.218005</td>\n",
       "      <td>-0.174360</td>\n",
       "      <td>-0.881879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01 00:04:00</td>\n",
       "      <td>-0.519607</td>\n",
       "      <td>-0.348889</td>\n",
       "      <td>-0.488696</td>\n",
       "      <td>-0.899130</td>\n",
       "      <td>-0.965723</td>\n",
       "      <td>-1.768380</td>\n",
       "      <td>-1.355009</td>\n",
       "      <td>0.707168</td>\n",
       "      <td>-1.053303</td>\n",
       "      <td>-0.841144</td>\n",
       "      <td>-0.761410</td>\n",
       "      <td>0.919308</td>\n",
       "      <td>2.041296</td>\n",
       "      <td>2.439081</td>\n",
       "      <td>2.377882</td>\n",
       "      <td>0.703416</td>\n",
       "      <td>0.510214</td>\n",
       "      <td>1.669767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time      PLN1      PLN2      PLN3      ULL1      ULL2  \\\n",
       "0  2020-06-01 00:00:00 -0.520051 -0.469417 -0.491179 -0.852017 -1.003068   \n",
       "1  2020-06-01 00:01:00 -0.518390 -0.469592 -0.485656 -0.905465 -1.016009   \n",
       "2  2020-06-01 00:02:00 -0.520102 -0.348132 -0.489844 -0.987181 -1.028018   \n",
       "3  2020-06-01 00:03:00 -0.515582 -0.349161 -0.488267 -0.814230 -0.926227   \n",
       "4  2020-06-01 00:04:00 -0.519607 -0.348889 -0.488696 -0.899130 -0.965723   \n",
       "\n",
       "       ULL3  COS_PHI1  COS_PHI2  COS_PHI3      FREQ     RC_DC     RC_AC  \\\n",
       "0 -1.783292 -1.338808 -1.189834 -0.885658 -0.479759 -0.761410  1.276387   \n",
       "1 -1.803094 -1.356629 -1.159350 -0.870606 -1.233069  0.728477 -0.330467   \n",
       "2 -1.808977 -1.303165  0.693881 -0.921471 -1.217799 -0.761410 -0.330467   \n",
       "3 -1.693993 -1.082826  0.575856 -0.936003 -0.871684  0.728477 -0.211441   \n",
       "4 -1.768380 -1.355009  0.707168 -1.053303 -0.841144 -0.761410  0.919308   \n",
       "\n",
       "    RC_50Hz  RC_150Hz  RC_<100Hz  RC_100Hz-1kHz  RC_>1kHz  RC_>10kHz  \n",
       "0  1.388355  1.509262   1.555410       1.427389  1.381491   2.307679  \n",
       "1 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
       "2 -0.570467 -0.350376  -0.254028      -0.283821 -0.298828  -0.881879  \n",
       "3  0.082473 -0.195407  -0.254028      -0.218005 -0.174360  -0.881879  \n",
       "4  2.041296  2.439081   2.377882       0.703416  0.510214   1.669767  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_weekend_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this moment we have six different datasets to use:\n",
    "* dataset_clean (Whole dataset)\n",
    "* dataset_weekdays (Entries from weekdays from 4:00 to 19:30)\n",
    "* dataset_weekend (Entries from Weekends and from weekdays from 19:30 to 4:00)\n",
    "* dataset_norm (Whole dataset, mean/stddev normalised)\n",
    "* dataset_weekdays_norm (Entries from weekdays from 4:00 to 19:30, mean/stddev normalised)\n",
    "* dataset_weekend_norm (Entries from Weekends and from weekdays from 19:30 to 4:00, mean/stddev normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We calculate the pearson correlation of all features and plot them into a heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between PLN1 and PLN1\n",
      "Correlation between PLN1 and PLN2\n",
      "0.9530638927686161\n",
      "Correlation between PLN1 and PLN3\n",
      "0.9606664987977854\n",
      "Correlation between PLN1 and ULL1\n",
      "-0.727401637634178\n",
      "Correlation between PLN1 and ULL2\n",
      "-0.6955282277514697\n",
      "Correlation between PLN1 and ULL3\n",
      "-0.7030835410050382\n",
      "Correlation between PLN1 and COS_PHI1\n",
      "0.8410401295195361\n",
      "Correlation between PLN1 and COS_PHI2\n",
      "0.6731338062873105\n",
      "Correlation between PLN1 and COS_PHI3\n",
      "0.8122370309192151\n",
      "Correlation between PLN1 and FREQ\n",
      "-0.1545159794969927\n",
      "Correlation between PLN1 and RC_DC\n",
      "0.041447902380906156\n",
      "Correlation between PLN1 and RC_AC\n",
      "0.6311099014117804\n",
      "Correlation between PLN1 and RC_50Hz\n",
      "0.3688113546135111\n",
      "Correlation between PLN1 and RC_150Hz\n",
      "0.5078743784519383\n",
      "Correlation between PLN1 and RC_<100Hz\n",
      "0.4309325330867659\n",
      "Correlation between PLN1 and RC_100Hz-1kHz\n",
      "0.6585953463453891\n",
      "Correlation between PLN1 and RC_>1kHz\n",
      "0.5928797475823843\n",
      "Correlation between PLN1 and RC_>10kHz\n",
      "0.3161918341465537\n",
      "Mean of PLN1 correlations: 0.5922655142470218\n",
      "\n",
      "Correlation between PLN2 and PLN1\n",
      "0.9530638927686161\n",
      "Correlation between PLN2 and PLN2\n",
      "Correlation between PLN2 and PLN3\n",
      "0.9452605980705133\n",
      "Correlation between PLN2 and ULL1\n",
      "-0.6920070109902806\n",
      "Correlation between PLN2 and ULL2\n",
      "-0.6704566233203504\n",
      "Correlation between PLN2 and ULL3\n",
      "-0.6734582119423181\n",
      "Correlation between PLN2 and COS_PHI1\n",
      "0.7986365971843634\n",
      "Correlation between PLN2 and COS_PHI2\n",
      "0.7023352006830496\n",
      "Correlation between PLN2 and COS_PHI3\n",
      "0.8038123821731533\n",
      "Correlation between PLN2 and FREQ\n",
      "-0.14213527867385353\n",
      "Correlation between PLN2 and RC_DC\n",
      "0.03920776273389812\n",
      "Correlation between PLN2 and RC_AC\n",
      "0.6232451337648502\n",
      "Correlation between PLN2 and RC_50Hz\n",
      "0.358995472175193\n",
      "Correlation between PLN2 and RC_150Hz\n",
      "0.49084689121247504\n",
      "Correlation between PLN2 and RC_<100Hz\n",
      "0.4172313931163454\n",
      "Correlation between PLN2 and RC_100Hz-1kHz\n",
      "0.6488235868701702\n",
      "Correlation between PLN2 and RC_>1kHz\n",
      "0.5891663952522228\n",
      "Correlation between PLN2 and RC_>10kHz\n",
      "0.3118843831224032\n",
      "Mean of PLN2 correlations: 0.5800333420031798\n",
      "\n",
      "Correlation between PLN3 and PLN1\n",
      "0.9606664987977854\n",
      "Correlation between PLN3 and PLN2\n",
      "0.9452605980705133\n",
      "Correlation between PLN3 and PLN3\n",
      "Correlation between PLN3 and ULL1\n",
      "-0.7002177438968474\n",
      "Correlation between PLN3 and ULL2\n",
      "-0.6722798995076357\n",
      "Correlation between PLN3 and ULL3\n",
      "-0.682115655836712\n",
      "Correlation between PLN3 and COS_PHI1\n",
      "0.8022338627218529\n",
      "Correlation between PLN3 and COS_PHI2\n",
      "0.6694582338358981\n",
      "Correlation between PLN3 and COS_PHI3\n",
      "0.8313797068885322\n",
      "Correlation between PLN3 and FREQ\n",
      "-0.14967487104652208\n",
      "Correlation between PLN3 and RC_DC\n",
      "0.04088450891644738\n",
      "Correlation between PLN3 and RC_AC\n",
      "0.628165773489285\n",
      "Correlation between PLN3 and RC_50Hz\n",
      "0.3656352287662712\n",
      "Correlation between PLN3 and RC_150Hz\n",
      "0.49896359795411904\n",
      "Correlation between PLN3 and RC_<100Hz\n",
      "0.42395344997898904\n",
      "Correlation between PLN3 and RC_100Hz-1kHz\n",
      "0.6539236685512879\n",
      "Correlation between PLN3 and RC_>1kHz\n",
      "0.5911138593179589\n",
      "Correlation between PLN3 and RC_>10kHz\n",
      "0.31781241506277863\n",
      "Mean of PLN3 correlations: 0.5843376219199669\n",
      "\n",
      "Correlation between ULL1 and PLN1\n",
      "-0.727401637634178\n",
      "Correlation between ULL1 and PLN2\n",
      "-0.6920070109902806\n",
      "Correlation between ULL1 and PLN3\n",
      "-0.7002177438968474\n",
      "Correlation between ULL1 and ULL1\n",
      "Correlation between ULL1 and ULL2\n",
      "0.9939941350683599\n",
      "Correlation between ULL1 and ULL3\n",
      "0.9618955396414085\n",
      "Correlation between ULL1 and COS_PHI1\n",
      "-0.6035602236966964\n",
      "Correlation between ULL1 and COS_PHI2\n",
      "-0.49980114685113497\n",
      "Correlation between ULL1 and COS_PHI3\n",
      "-0.5935572901249869\n",
      "Correlation between ULL1 and FREQ\n",
      "0.13197327822064742\n",
      "Correlation between ULL1 and RC_DC\n",
      "-0.019422769445639664\n",
      "Correlation between ULL1 and RC_AC\n",
      "-0.4224120693563288\n",
      "Correlation between ULL1 and RC_50Hz\n",
      "-0.27779168346606614\n",
      "Correlation between ULL1 and RC_150Hz\n",
      "-0.3920273758128221\n",
      "Correlation between ULL1 and RC_<100Hz\n",
      "-0.32940535648076164\n",
      "Correlation between ULL1 and RC_100Hz-1kHz\n",
      "-0.43980057374684034\n",
      "Correlation between ULL1 and RC_>1kHz\n",
      "-0.37447740688167563\n",
      "Correlation between ULL1 and RC_>10kHz\n",
      "-0.25420475464234843\n",
      "Mean of ULL1 correlations: 0.4949382350562954\n",
      "\n",
      "Correlation between ULL2 and PLN1\n",
      "-0.6955282277514697\n",
      "Correlation between ULL2 and PLN2\n",
      "-0.6704566233203504\n",
      "Correlation between ULL2 and PLN3\n",
      "-0.6722798995076357\n",
      "Correlation between ULL2 and ULL1\n",
      "0.9939941350683599\n",
      "Correlation between ULL2 and ULL2\n",
      "Correlation between ULL2 and ULL3\n",
      "0.9679344064619084\n",
      "Correlation between ULL2 and COS_PHI1\n",
      "-0.5720923780407855\n",
      "Correlation between ULL2 and COS_PHI2\n",
      "-0.47937831082658805\n",
      "Correlation between ULL2 and COS_PHI3\n",
      "-0.5677001126696039\n",
      "Correlation between ULL2 and FREQ\n",
      "0.1223444971347323\n",
      "Correlation between ULL2 and RC_DC\n",
      "-0.01568546341238987\n",
      "Correlation between ULL2 and RC_AC\n",
      "-0.4042360054210484\n",
      "Correlation between ULL2 and RC_50Hz\n",
      "-0.27269488072813725\n",
      "Correlation between ULL2 and RC_150Hz\n",
      "-0.3823625567194394\n",
      "Correlation between ULL2 and RC_<100Hz\n",
      "-0.32256670279212474\n",
      "Correlation between ULL2 and RC_100Hz-1kHz\n",
      "-0.42008689401137744\n",
      "Correlation between ULL2 and RC_>1kHz\n",
      "-0.35767437058385204\n",
      "Correlation between ULL2 and RC_>10kHz\n",
      "-0.24924688411542367\n",
      "Mean of ULL2 correlations: 0.4803683734450133\n",
      "\n",
      "Correlation between ULL3 and PLN1\n",
      "-0.7030835410050382\n",
      "Correlation between ULL3 and PLN2\n",
      "-0.6734582119423181\n",
      "Correlation between ULL3 and PLN3\n",
      "-0.682115655836712\n",
      "Correlation between ULL3 and ULL1\n",
      "0.9618955396414085\n",
      "Correlation between ULL3 and ULL2\n",
      "0.9679344064619084\n",
      "Correlation between ULL3 and ULL3\n",
      "Correlation between ULL3 and COS_PHI1\n",
      "-0.5631552795349813\n",
      "Correlation between ULL3 and COS_PHI2\n",
      "-0.46056835494110226\n",
      "Correlation between ULL3 and COS_PHI3\n",
      "-0.5678746499327131\n",
      "Correlation between ULL3 and FREQ\n",
      "0.1173225350558848\n",
      "Correlation between ULL3 and RC_DC\n",
      "-0.018546293523528327\n",
      "Correlation between ULL3 and RC_AC\n",
      "-0.4237420880482717\n",
      "Correlation between ULL3 and RC_50Hz\n",
      "-0.297245853712721\n",
      "Correlation between ULL3 and RC_150Hz\n",
      "-0.4149620582027391\n",
      "Correlation between ULL3 and RC_<100Hz\n",
      "-0.35093038054779235\n",
      "Correlation between ULL3 and RC_100Hz-1kHz\n",
      "-0.44085919789991945\n",
      "Correlation between ULL3 and RC_>1kHz\n",
      "-0.3748521278843219\n",
      "Correlation between ULL3 and RC_>10kHz\n",
      "-0.24276692772497824\n",
      "Mean of ULL3 correlations: 0.48595959422919643\n",
      "\n",
      "Correlation between COS_PHI1 and PLN1\n",
      "0.8410401295195361\n",
      "Correlation between COS_PHI1 and PLN2\n",
      "0.7986365971843634\n",
      "Correlation between COS_PHI1 and PLN3\n",
      "0.8022338627218529\n",
      "Correlation between COS_PHI1 and ULL1\n",
      "-0.6035602236966964\n",
      "Correlation between COS_PHI1 and ULL2\n",
      "-0.5720923780407855\n",
      "Correlation between COS_PHI1 and ULL3\n",
      "-0.5631552795349813\n",
      "Correlation between COS_PHI1 and COS_PHI1\n",
      "Correlation between COS_PHI1 and COS_PHI2\n",
      "0.6721486971436307\n",
      "Correlation between COS_PHI1 and COS_PHI3\n",
      "0.7679288479423112\n",
      "Correlation between COS_PHI1 and FREQ\n",
      "-0.14703514716770288\n",
      "Correlation between COS_PHI1 and RC_DC\n",
      "0.028560806482742673\n",
      "Correlation between COS_PHI1 and RC_AC\n",
      "0.5224505954850466\n",
      "Correlation between COS_PHI1 and RC_50Hz\n",
      "0.28598483106508676\n",
      "Correlation between COS_PHI1 and RC_150Hz\n",
      "0.40690341488990583\n",
      "Correlation between COS_PHI1 and RC_<100Hz\n",
      "0.34506225421962555\n",
      "Correlation between COS_PHI1 and RC_100Hz-1kHz\n",
      "0.5443587853537231\n",
      "Correlation between COS_PHI1 and RC_>1kHz\n",
      "0.4936793319894299\n",
      "Correlation between COS_PHI1 and RC_>10kHz\n",
      "0.27038433727544114\n",
      "Mean of COS_PHI1 correlations: 0.5097185599831096\n",
      "\n",
      "Correlation between COS_PHI2 and PLN1\n",
      "0.6731338062873105\n",
      "Correlation between COS_PHI2 and PLN2\n",
      "0.7023352006830496\n",
      "Correlation between COS_PHI2 and PLN3\n",
      "0.6694582338358981\n",
      "Correlation between COS_PHI2 and ULL1\n",
      "-0.49980114685113497\n",
      "Correlation between COS_PHI2 and ULL2\n",
      "-0.47937831082658805\n",
      "Correlation between COS_PHI2 and ULL3\n",
      "-0.46056835494110226\n",
      "Correlation between COS_PHI2 and COS_PHI1\n",
      "0.6721486971436307\n",
      "Correlation between COS_PHI2 and COS_PHI2\n",
      "Correlation between COS_PHI2 and COS_PHI3\n",
      "0.6853907893926214\n",
      "Correlation between COS_PHI2 and FREQ\n",
      "-0.11239331571367378\n",
      "Correlation between COS_PHI2 and RC_DC\n",
      "0.02451230427875363\n",
      "Correlation between COS_PHI2 and RC_AC\n",
      "0.42957439337353404\n",
      "Correlation between COS_PHI2 and RC_50Hz\n",
      "0.25029130339434147\n",
      "Correlation between COS_PHI2 and RC_150Hz\n",
      "0.3449231044067341\n",
      "Correlation between COS_PHI2 and RC_<100Hz\n",
      "0.29451321192232666\n",
      "Correlation between COS_PHI2 and RC_100Hz-1kHz\n",
      "0.44658403290924636\n",
      "Correlation between COS_PHI2 and RC_>1kHz\n",
      "0.405428891306359\n",
      "Correlation between COS_PHI2 and RC_>10kHz\n",
      "0.2320070395080783\n",
      "Mean of COS_PHI2 correlations: 0.434261302163199\n",
      "\n",
      "Correlation between COS_PHI3 and PLN1\n",
      "0.8122370309192151\n",
      "Correlation between COS_PHI3 and PLN2\n",
      "0.8038123821731533\n",
      "Correlation between COS_PHI3 and PLN3\n",
      "0.8313797068885322\n",
      "Correlation between COS_PHI3 and ULL1\n",
      "-0.5935572901249869\n",
      "Correlation between COS_PHI3 and ULL2\n",
      "-0.5677001126696039\n",
      "Correlation between COS_PHI3 and ULL3\n",
      "-0.5678746499327131\n",
      "Correlation between COS_PHI3 and COS_PHI1\n",
      "0.7679288479423112\n",
      "Correlation between COS_PHI3 and COS_PHI2\n",
      "0.6853907893926214\n",
      "Correlation between COS_PHI3 and COS_PHI3\n",
      "Correlation between COS_PHI3 and FREQ\n",
      "-0.13593458098321448\n",
      "Correlation between COS_PHI3 and RC_DC\n",
      "0.03770701540947715\n",
      "Correlation between COS_PHI3 and RC_AC\n",
      "0.5128776647152183\n",
      "Correlation between COS_PHI3 and RC_50Hz\n",
      "0.2954004112175189\n",
      "Correlation between COS_PHI3 and RC_150Hz\n",
      "0.41614317393217437\n",
      "Correlation between COS_PHI3 and RC_<100Hz\n",
      "0.3510288668281723\n",
      "Correlation between COS_PHI3 and RC_100Hz-1kHz\n",
      "0.5325198797906967\n",
      "Correlation between COS_PHI3 and RC_>1kHz\n",
      "0.4825962763757616\n",
      "Correlation between COS_PHI3 and RC_>10kHz\n",
      "0.2591023016571137\n",
      "Mean of COS_PHI3 correlations: 0.5090112341736757\n",
      "\n",
      "Correlation between FREQ and PLN1\n",
      "-0.1545159794969927\n",
      "Correlation between FREQ and PLN2\n",
      "-0.14213527867385353\n",
      "Correlation between FREQ and PLN3\n",
      "-0.14967487104652208\n",
      "Correlation between FREQ and ULL1\n",
      "0.13197327822064742\n",
      "Correlation between FREQ and ULL2\n",
      "0.1223444971347323\n",
      "Correlation between FREQ and ULL3\n",
      "0.1173225350558848\n",
      "Correlation between FREQ and COS_PHI1\n",
      "-0.14703514716770288\n",
      "Correlation between FREQ and COS_PHI2\n",
      "-0.11239331571367378\n",
      "Correlation between FREQ and COS_PHI3\n",
      "-0.13593458098321448\n",
      "Correlation between FREQ and FREQ\n",
      "Correlation between FREQ and RC_DC\n",
      "-0.010809999367105865\n",
      "Correlation between FREQ and RC_AC\n",
      "-0.10768675608573988\n",
      "Correlation between FREQ and RC_50Hz\n",
      "-0.059954061740045236\n",
      "Correlation between FREQ and RC_150Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07462007247264732\n",
      "Correlation between FREQ and RC_<100Hz\n",
      "-0.058979144441292104\n",
      "Correlation between FREQ and RC_100Hz-1kHz\n",
      "-0.11163642547386084\n",
      "Correlation between FREQ and RC_>1kHz\n",
      "-0.10135632693877397\n",
      "Correlation between FREQ and RC_>10kHz\n",
      "-0.044164438899609276\n",
      "Mean of FREQ correlations: 0.10485510052425284\n",
      "\n",
      "Correlation between RC_DC and PLN1\n",
      "0.041447902380906156\n",
      "Correlation between RC_DC and PLN2\n",
      "0.03920776273389812\n",
      "Correlation between RC_DC and PLN3\n",
      "0.04088450891644738\n",
      "Correlation between RC_DC and ULL1\n",
      "-0.019422769445639664\n",
      "Correlation between RC_DC and ULL2\n",
      "-0.01568546341238987\n",
      "Correlation between RC_DC and ULL3\n",
      "-0.018546293523528327\n",
      "Correlation between RC_DC and COS_PHI1\n",
      "0.028560806482742673\n",
      "Correlation between RC_DC and COS_PHI2\n",
      "0.02451230427875363\n",
      "Correlation between RC_DC and COS_PHI3\n",
      "0.03770701540947715\n",
      "Correlation between RC_DC and FREQ\n",
      "-0.010809999367105865\n",
      "Correlation between RC_DC and RC_DC\n",
      "Correlation between RC_DC and RC_AC\n",
      "0.00940827540060927\n",
      "Correlation between RC_DC and RC_50Hz\n",
      "-0.06680533222157001\n",
      "Correlation between RC_DC and RC_150Hz\n",
      "-0.06653181935938089\n",
      "Correlation between RC_DC and RC_<100Hz\n",
      "-0.08081309086755882\n",
      "Correlation between RC_DC and RC_100Hz-1kHz\n",
      "0.01573317644502214\n",
      "Correlation between RC_DC and RC_>1kHz\n",
      "0.011862953683483885\n",
      "Correlation between RC_DC and RC_>10kHz\n",
      "-0.0770704801959081\n",
      "Mean of RC_DC correlations: 0.035588820830848356\n",
      "\n",
      "Correlation between RC_AC and PLN1\n",
      "0.6311099014117804\n",
      "Correlation between RC_AC and PLN2\n",
      "0.6232451337648502\n",
      "Correlation between RC_AC and PLN3\n",
      "0.628165773489285\n",
      "Correlation between RC_AC and ULL1\n",
      "-0.4224120693563288\n",
      "Correlation between RC_AC and ULL2\n",
      "-0.4042360054210484\n",
      "Correlation between RC_AC and ULL3\n",
      "-0.4237420880482717\n",
      "Correlation between RC_AC and COS_PHI1\n",
      "0.5224505954850466\n",
      "Correlation between RC_AC and COS_PHI2\n",
      "0.42957439337353404\n",
      "Correlation between RC_AC and COS_PHI3\n",
      "0.5128776647152183\n",
      "Correlation between RC_AC and FREQ\n",
      "-0.10768675608573988\n",
      "Correlation between RC_AC and RC_DC\n",
      "0.00940827540060927\n",
      "Correlation between RC_AC and RC_AC\n",
      "Correlation between RC_AC and RC_50Hz\n",
      "0.5988353180559401\n",
      "Correlation between RC_AC and RC_150Hz\n",
      "0.6870800166525869\n",
      "Correlation between RC_AC and RC_<100Hz\n",
      "0.647849754054101\n",
      "Correlation between RC_AC and RC_100Hz-1kHz\n",
      "0.9937633088247756\n",
      "Correlation between RC_AC and RC_>1kHz\n",
      "0.9856775813519927\n",
      "Correlation between RC_AC and RC_>10kHz\n",
      "0.6405906580239061\n",
      "Mean of RC_AC correlations: 0.5452179584420598\n",
      "\n",
      "Correlation between RC_50Hz and PLN1\n",
      "0.3688113546135111\n",
      "Correlation between RC_50Hz and PLN2\n",
      "0.358995472175193\n",
      "Correlation between RC_50Hz and PLN3\n",
      "0.3656352287662712\n",
      "Correlation between RC_50Hz and ULL1\n",
      "-0.27779168346606614\n",
      "Correlation between RC_50Hz and ULL2\n",
      "-0.27269488072813725\n",
      "Correlation between RC_50Hz and ULL3\n",
      "-0.297245853712721\n",
      "Correlation between RC_50Hz and COS_PHI1\n",
      "0.28598483106508676\n",
      "Correlation between RC_50Hz and COS_PHI2\n",
      "0.25029130339434147\n",
      "Correlation between RC_50Hz and COS_PHI3\n",
      "0.2954004112175189\n",
      "Correlation between RC_50Hz and FREQ\n",
      "-0.059954061740045236\n",
      "Correlation between RC_50Hz and RC_DC\n",
      "-0.06680533222157001\n",
      "Correlation between RC_50Hz and RC_AC\n",
      "0.5988353180559401\n",
      "Correlation between RC_50Hz and RC_50Hz\n",
      "Correlation between RC_50Hz and RC_150Hz\n",
      "0.9325844626970944\n",
      "Correlation between RC_50Hz and RC_<100Hz\n",
      "0.9378468651085988\n",
      "Correlation between RC_50Hz and RC_100Hz-1kHz\n",
      "0.5680814090699109\n",
      "Correlation between RC_50Hz and RC_>1kHz\n",
      "0.5226845889912005\n",
      "Correlation between RC_50Hz and RC_>10kHz\n",
      "0.821594325170042\n",
      "Mean of RC_50Hz correlations: 0.4283080813054852\n",
      "\n",
      "Correlation between RC_150Hz and PLN1\n",
      "0.5078743784519383\n",
      "Correlation between RC_150Hz and PLN2\n",
      "0.49084689121247504\n",
      "Correlation between RC_150Hz and PLN3\n",
      "0.49896359795411904\n",
      "Correlation between RC_150Hz and ULL1\n",
      "-0.3920273758128221\n",
      "Correlation between RC_150Hz and ULL2\n",
      "-0.3823625567194394\n",
      "Correlation between RC_150Hz and ULL3\n",
      "-0.4149620582027391\n",
      "Correlation between RC_150Hz and COS_PHI1\n",
      "0.40690341488990583\n",
      "Correlation between RC_150Hz and COS_PHI2\n",
      "0.3449231044067341\n",
      "Correlation between RC_150Hz and COS_PHI3\n",
      "0.41614317393217437\n",
      "Correlation between RC_150Hz and FREQ\n",
      "-0.07462007247264732\n",
      "Correlation between RC_150Hz and RC_DC\n",
      "-0.06653181935938089\n",
      "Correlation between RC_150Hz and RC_AC\n",
      "0.6870800166525869\n",
      "Correlation between RC_150Hz and RC_50Hz\n",
      "0.9325844626970944\n",
      "Correlation between RC_150Hz and RC_150Hz\n",
      "Correlation between RC_150Hz and RC_<100Hz\n",
      "0.9869431585782874\n",
      "Correlation between RC_150Hz and RC_100Hz-1kHz\n",
      "0.6594755799243152\n",
      "Correlation between RC_150Hz and RC_>1kHz\n",
      "0.6031328223115234\n",
      "Correlation between RC_150Hz and RC_>10kHz\n",
      "0.8525990801808159\n",
      "Mean of RC_150Hz correlations: 0.5128219743387646\n",
      "\n",
      "Correlation between RC_<100Hz and PLN1\n",
      "0.4309325330867659\n",
      "Correlation between RC_<100Hz and PLN2\n",
      "0.4172313931163454\n",
      "Correlation between RC_<100Hz and PLN3\n",
      "0.42395344997898904\n",
      "Correlation between RC_<100Hz and ULL1\n",
      "-0.32940535648076164\n",
      "Correlation between RC_<100Hz and ULL2\n",
      "-0.32256670279212474\n",
      "Correlation between RC_<100Hz and ULL3\n",
      "-0.35093038054779235\n",
      "Correlation between RC_<100Hz and COS_PHI1\n",
      "0.34506225421962555\n",
      "Correlation between RC_<100Hz and COS_PHI2\n",
      "0.29451321192232666\n",
      "Correlation between RC_<100Hz and COS_PHI3\n",
      "0.3510288668281723\n",
      "Correlation between RC_<100Hz and FREQ\n",
      "-0.058979144441292104\n",
      "Correlation between RC_<100Hz and RC_DC\n",
      "-0.08081309086755882\n",
      "Correlation between RC_<100Hz and RC_AC\n",
      "0.647849754054101\n",
      "Correlation between RC_<100Hz and RC_50Hz\n",
      "0.9378468651085988\n",
      "Correlation between RC_<100Hz and RC_150Hz\n",
      "0.9869431585782874\n",
      "Correlation between RC_<100Hz and RC_<100Hz\n",
      "Correlation between RC_<100Hz and RC_100Hz-1kHz\n",
      "0.6163156439742201\n",
      "Correlation between RC_<100Hz and RC_>1kHz\n",
      "0.5681934410881463\n",
      "Correlation between RC_<100Hz and RC_>10kHz\n",
      "0.8697462185366154\n",
      "Mean of RC_<100Hz correlations: 0.4724889097424544\n",
      "\n",
      "Correlation between RC_100Hz-1kHz and PLN1\n",
      "0.6585953463453891\n",
      "Correlation between RC_100Hz-1kHz and PLN2\n",
      "0.6488235868701702\n",
      "Correlation between RC_100Hz-1kHz and PLN3\n",
      "0.6539236685512879\n",
      "Correlation between RC_100Hz-1kHz and ULL1\n",
      "-0.43980057374684034\n",
      "Correlation between RC_100Hz-1kHz and ULL2\n",
      "-0.42008689401137744\n",
      "Correlation between RC_100Hz-1kHz and ULL3\n",
      "-0.44085919789991945\n",
      "Correlation between RC_100Hz-1kHz and COS_PHI1\n",
      "0.5443587853537231\n",
      "Correlation between RC_100Hz-1kHz and COS_PHI2\n",
      "0.44658403290924636\n",
      "Correlation between RC_100Hz-1kHz and COS_PHI3\n",
      "0.5325198797906967\n",
      "Correlation between RC_100Hz-1kHz and FREQ\n",
      "-0.11163642547386084\n",
      "Correlation between RC_100Hz-1kHz and RC_DC\n",
      "0.01573317644502214\n",
      "Correlation between RC_100Hz-1kHz and RC_AC\n",
      "0.9937633088247756\n",
      "Correlation between RC_100Hz-1kHz and RC_50Hz\n",
      "0.5680814090699109\n",
      "Correlation between RC_100Hz-1kHz and RC_150Hz\n",
      "0.6594755799243152\n",
      "Correlation between RC_100Hz-1kHz and RC_<100Hz\n",
      "0.6163156439742201\n",
      "Correlation between RC_100Hz-1kHz and RC_100Hz-1kHz\n",
      "Correlation between RC_100Hz-1kHz and RC_>1kHz\n",
      "0.9842987879976395\n",
      "Correlation between RC_100Hz-1kHz and RC_>10kHz\n",
      "0.6079125821841566\n",
      "Mean of RC_100Hz-1kHz correlations: 0.5495746399630912\n",
      "\n",
      "Correlation between RC_>1kHz and PLN1\n",
      "0.5928797475823843\n",
      "Correlation between RC_>1kHz and PLN2\n",
      "0.5891663952522228\n",
      "Correlation between RC_>1kHz and PLN3\n",
      "0.5911138593179589\n",
      "Correlation between RC_>1kHz and ULL1\n",
      "-0.37447740688167563\n",
      "Correlation between RC_>1kHz and ULL2\n",
      "-0.35767437058385204\n",
      "Correlation between RC_>1kHz and ULL3\n",
      "-0.3748521278843219\n",
      "Correlation between RC_>1kHz and COS_PHI1\n",
      "0.4936793319894299\n",
      "Correlation between RC_>1kHz and COS_PHI2\n",
      "0.405428891306359\n",
      "Correlation between RC_>1kHz and COS_PHI3\n",
      "0.4825962763757616\n",
      "Correlation between RC_>1kHz and FREQ\n",
      "-0.10135632693877397\n",
      "Correlation between RC_>1kHz and RC_DC\n",
      "0.011862953683483885\n",
      "Correlation between RC_>1kHz and RC_AC\n",
      "0.9856775813519927\n",
      "Correlation between RC_>1kHz and RC_50Hz\n",
      "0.5226845889912005\n",
      "Correlation between RC_>1kHz and RC_150Hz\n",
      "0.6031328223115234\n",
      "Correlation between RC_>1kHz and RC_<100Hz\n",
      "0.5681934410881463\n",
      "Correlation between RC_>1kHz and RC_100Hz-1kHz\n",
      "0.9842987879976395\n",
      "Correlation between RC_>1kHz and RC_>1kHz\n",
      "Correlation between RC_>1kHz and RC_>10kHz\n",
      "0.5866515939691285\n",
      "Mean of RC_>1kHz correlations: 0.507395676676815\n",
      "\n",
      "Correlation between RC_>10kHz and PLN1\n",
      "0.3161918341465537\n",
      "Correlation between RC_>10kHz and PLN2\n",
      "0.3118843831224032\n",
      "Correlation between RC_>10kHz and PLN3\n",
      "0.31781241506277863\n",
      "Correlation between RC_>10kHz and ULL1\n",
      "-0.25420475464234843\n",
      "Correlation between RC_>10kHz and ULL2\n",
      "-0.24924688411542367\n",
      "Correlation between RC_>10kHz and ULL3\n",
      "-0.24276692772497824\n",
      "Correlation between RC_>10kHz and COS_PHI1\n",
      "0.27038433727544114\n",
      "Correlation between RC_>10kHz and COS_PHI2\n",
      "0.2320070395080783\n",
      "Correlation between RC_>10kHz and COS_PHI3\n",
      "0.2591023016571137\n",
      "Correlation between RC_>10kHz and FREQ\n",
      "-0.044164438899609276\n",
      "Correlation between RC_>10kHz and RC_DC\n",
      "-0.0770704801959081\n",
      "Correlation between RC_>10kHz and RC_AC\n",
      "0.6405906580239061\n",
      "Correlation between RC_>10kHz and RC_50Hz\n",
      "0.821594325170042\n",
      "Correlation between RC_>10kHz and RC_150Hz\n",
      "0.8525990801808159\n",
      "Correlation between RC_>10kHz and RC_<100Hz\n",
      "0.8697462185366154\n",
      "Correlation between RC_>10kHz and RC_100Hz-1kHz\n",
      "0.6079125821841566\n",
      "Correlation between RC_>10kHz and RC_>1kHz\n",
      "0.5866515939691285\n",
      "Correlation between RC_>10kHz and RC_>10kHz\n",
      "Mean of RC_>10kHz correlations: 0.4090547208479589\n",
      "\n",
      "Mean of all correlations: 0.45756664777179923\n"
     ]
    }
   ],
   "source": [
    "correlations = []\n",
    "matrix = []\n",
    "\n",
    "for i in dataset_norm.columns[1:]:\n",
    "  feature = []\n",
    "  for j in dataset_norm.columns[1:]:\n",
    "    print(f'Correlation between {i} and {j}')\n",
    "    correlation = stats.pearsonr(dataset_norm[i], dataset_norm[j])[0]\n",
    "    if i != j:\n",
    "      correlations.append(abs(correlation))\n",
    "      feature.append(abs(correlation))\n",
    "      print(correlation)\n",
    "  print(f'Mean of {i} correlations: {np.mean(feature)}')\n",
    "  print('')\n",
    "  matrix.append(feature)\n",
    "\n",
    "print(f'Mean of all correlations: {np.mean(correlations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features correlations heat map\n",
    "corr = dataset_norm.corr()\n",
    "sns.heatmap(corr,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained_variance 1 principal component: 0.5317647804810048 (accumulated 0.5318)\n",
      "Explained_variance 2 principal component: 0.16335739298653532 (accumulated 0.6951)\n",
      "Explained_variance 3 principal component: 0.07511546472382856 (accumulated 0.7702)\n",
      "Explained_variance 4 principal component: 0.05492162706805076 (accumulated 0.8252)\n",
      "Explained_variance 5 principal component: 0.053906168670763664 (accumulated 0.8791)\n",
      "Explained_variance 6 principal component: 0.04952232661739574 (accumulated 0.9286)\n",
      "Explained_variance 7 principal component: 0.02248634946399496 (accumulated 0.9511)\n",
      "Explained_variance 8 principal component: 0.01393273190213723 (accumulated 0.965)\n",
      "Explained_variance 9 principal component: 0.012792662672299494 (accumulated 0.9778)\n",
      "Explained_variance 10 principal component: 0.009829012007200738 (accumulated 0.9876)\n",
      "Explained_variance 11 principal component: 0.004024926426955841 (accumulated 0.9917)\n",
      "Explained_variance 12 principal component: 0.002893959610103222 (accumulated 0.9945)\n",
      "Explained_variance 13 principal component: 0.002163271201445784 (accumulated 0.9967)\n",
      "Explained_variance 14 principal component: 0.0017411162226414235 (accumulated 0.9985)\n",
      "Explained_variance 15 principal component: 0.0006928432299862185 (accumulated 0.9991)\n",
      "Explained_variance 16 principal component: 0.00021826337426099308 (accumulated 0.9994)\n",
      "Explained_variance 17 principal component: 0.00023351820917083966 (accumulated 0.9996)\n",
      "Explained_variance 18 principal component: 0.00040358513222440485 (accumulated 1.0)\n"
     ]
    }
   ],
   "source": [
    "# 协方差矩阵、特征值和解释方差\n",
    "\n",
    "covmatrix = dataset_norm.cov()\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covmatrix)\n",
    "\n",
    "acc = 0\n",
    "\n",
    "acc_variance = []\n",
    "\n",
    "for i, eigen in enumerate(eigenvalues):\n",
    "  acc += eigen/np.sum(eigenvalues)\n",
    "  acc_variance.append(acc)\n",
    "  print(f'Explained_variance {i +1} principal component: {eigen/np.sum(eigenvalues)} (accumulated {round(acc, 4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "a = acc_variance\n",
    "\n",
    "b = [i +1 for i in range(len(acc_variance))]\n",
    "plt.title('Explained variance over number of principal components')\n",
    "plt.xlabel('18 principal components')\n",
    "plt.xticks(b)\n",
    "plt.ylabel('explained variance')\n",
    "plt.bar(b, a,color='wheat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create a Baseline Model\n",
    "\n",
    "I am taking the Last step as prediction of all features to create a baselinemodel. I will use this baseline model to compare the results of the actual model with it. Everything that works better than this baseline model could be an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 63359/63359 [00:15<00:00, 4092.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set: 57023\n",
      "length of test set: 6336\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader_train, loader_test = utils_bsc.create_dataloaders(dataset=dataset_norm, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Baseline model based in: Output element is the Input element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses_train = []\n",
    "\n",
    "for i in loader_train:\n",
    "  output = i[0]\n",
    "  target = i[1]\n",
    "  loss = criterion(output, target)\n",
    "  losses_train.append(loss.item())\n",
    "\n",
    "losses_test = []\n",
    "\n",
    "for i in loader_test:\n",
    "  output = i[0]\n",
    "  target = i[1]\n",
    "  loss = criterion(output, target)\n",
    "  losses_test.append(loss.item())\n",
    "\n",
    "# save to npy file to keep track of the results and to print graphs\n",
    "np.save(saved_results + '/baseline_train.npy', losses_train)\n",
    "np.save(saved_results + '/baseline_test.npy', losses_test)\n",
    "\n",
    "if colab is True:\n",
    "    files.download(saved_results + '/baseline_train.npy')\n",
    "    files.download(saved_results + '/baseline_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "Mean Loss of baselinemodel:  0.4729318470661722\n",
      "Standard deviation Loss of baselinemodel:  0.17852527679205688\n",
      "\n",
      "\n",
      "Test set\n",
      "Mean Loss of baselinemodel:  0.47363791067266103\n",
      "Standard deviation Loss of baselinemodel:  0.1742641143194265\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set\")\n",
    "print(\"Mean Loss of baselinemodel: \", np.mean(losses_train))\n",
    "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_train))\n",
    "print('\\n')\n",
    "print(\"Test set\")\n",
    "print(\"Mean Loss of baselinemodel: \", np.mean(losses_test))\n",
    "print(\"Standard deviation Loss of baselinemodel: \", np.std(losses_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a second baseline model based on a FFN. It predicts output element based on input element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ANN_relu\n",
      "237898 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "start_train_FFN = False\n",
    "\n",
    "# Create model FFN instance\n",
    "model_FFN = utils_bsc.ANN_relu(18, 18).to(device)\n",
    "\n",
    "print(f'Model: {type(model_FFN).__name__}')\n",
    "print(f'{utils_bsc.count_parameters(model_FFN)} trainable parameters.')\n",
    "\n",
    "# Define Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define Optimizer\n",
    "learning_rate=0.01\n",
    "optimizer_whole = torch.optim.SGD(model_FFN.parameters(), lr=learning_rate)\n",
    "\n",
    "if start_train_FFN is True:\n",
    "    n_epochs = 1\n",
    "\n",
    "    params_not_trained_whole = model_FFN.parameters()\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    best_results , train_losses_FFN, test_losses_FFN = utils_bsc.train_FFN(model_FFN, criterion, optimizer_whole, loader_train, loader_test, n_epochs)\n",
    "\n",
    "    model_FFN = best_results[0]\n",
    "    best_train_loss = best_results[1]\n",
    "    best_test_loss = best_results[2]\n",
    "    best_epoch_number = best_results[3]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    time_diff = (end_time - start_time)\n",
    "    execution_time = time_diff.total_seconds()\n",
    "\n",
    "    print(f'Best test loss at epoch {best_epoch_number}')\n",
    "    print(f'Train Loss: {best_train_loss}')\n",
    "    print(f'Test Loss: {best_test_loss}')\n",
    "    print(f'\\nTraining time for {n_epochs} epochs: {execution_time} seconds')\n",
    "\n",
    "\n",
    "    # save to npy file\n",
    "    np.save(saved_results + '/FFN_train.npy', train_losses_FFN)\n",
    "    np.save(saved_results + '/FFN_test.npy', test_losses_FFN)\n",
    "    torch.save(model_FFN, saved_results + '/model_FFN.pt')\n",
    "\n",
    "    if colab is True:\n",
    "\n",
    "        from google.colab import files\n",
    "\n",
    "        files.download(saved_results + '/FFN_train.npy')\n",
    "        files.download(saved_results + '/FFN_test.npy')\n",
    "        files.download(saved_results + '/model_FFN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if start_train_FFN is True:\n",
    "    baseline_loss = [np.mean(losses_train) for i in range(len(train_losses_FFN))]\n",
    "    utils_bsc.print_results_training(train_loss=train_losses_FFN, test_loss=test_losses_FFN, test_loss_baseline=baseline_loss, baseline_label='Baseline', title=\"Full Forward Neural Network train results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transformer Model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we train the actual transformer over the data set and print and store the results in a dictionary and in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_results_transformers ={}\n",
    "models={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train Transformer 'Vanilla' model, with standard hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "models = {name: [number_of_encoder_layers, number_of_decoder_layers, number_of_heads, optimizer, learning_rate, momentum, train_model, sequence_length, batch_size]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#models = {'vanilla': [6, 1, 6, 2048, 'SGD', 0.01, None, True, 30, 16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if models['vanilla'][7] is True:\n",
    "\n",
    "#     baseline_loss = [np.mean(i) for i in test_losses_FFN]\n",
    "#     utils_bsc.print_results_training(train_loss=training_results_transformers['vanilla'][4], test_loss=training_results_transformers['vanilla'][5], test_loss_baseline=baseline_loss, baseline_label='FFN Test Loss', title=\"Training results \" + 'vanilla' + \" Transformer (\" + str(models['vanilla'][0]) + \" encoder layers, \" + str(models['vanilla'][1]) + \" decoder layer, \" + str(models['vanilla'][2]) + \" heads. \" + models['vanilla'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models['vanilla'][7] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train same transformer model but this time with ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models['ADAM'] = [6, 1, 6, 2048, 'ADAM', 0.001, None, True, 30, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if models['ADAM'][7] is True:\n",
    "\n",
    "#     baseline_loss = [np.mean(i) for i in training_results_transformers['vanilla'][5]]\n",
    "#     utils_bsc.print_results_training(train_loss=training_results_transformers['ADAM'][4], test_loss=training_results_transformers['ADAM'][5], test_loss_baseline=baseline_loss, baseline_label='Vanilla transformer Test Loss', title=\"Training results \" + 'ADAM' + \" Transformer (\" + str(models['ADAM'][0]) + \" encoder layers, \" + str(models['ADAM'][1]) + \" decoder layer, \" + str(models['ADAM'][2]) + \" heads. \" + models['ADAM'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models['ADAM'][7] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train same transformer but with SGD with momentum as optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models['Momentum'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 30, 16]\n",
    "models['Momentum'][7] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if models['Momentum'][7] is True:\n",
    "\n",
    "    baseline_loss = [np.mean(i) for i in training_results_transformers['vanilla'][5]]\n",
    "    utils_bsc.print_results_training(train_loss=training_results_transformers['Momentum'][4], test_loss=training_results_transformers['Momentum'][5], test_loss_baseline=baseline_loss, baseline_label='Vanilla transformer Test Loss', title=\"Training results \" + 'Momentum' + \" Transformer (\" + str(models['Momentum'][0]) + \" encoder layers, \" + str(models['Momentum'][1]) + \" decoder layer, \" + str(models['Momentum'][2]) + \" heads. \" + models['Momentum'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models['Momentum'][7] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train the smallest transformer model with SGD with momentum as optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models['smallest'] = [1, 1, 1, 512, 'SGD', 0.001, 0.9, True, 30, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/test data loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 63329/63329 [00:52<00:00, 1210.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 30\n",
      "Batch size: 16\n",
      "length of training set: 56996\n",
      "length of test set: 6333\n",
      "\n",
      "\n",
      "Model: Transformer - smallest\n",
      "42208 trainable parameters.\n",
      "Epoch: 1 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:54<00:00, 65.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:23<00:00, 151.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.41727301700460484\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 156.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.42456898172244883\n",
      "\n",
      "\n",
      "Epoch: 2 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:53<00:00, 66.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:24<00:00, 144.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.38428364893609207\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 140.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3908538807070617\n",
      "\n",
      "\n",
      "Epoch: 3 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:57<00:00, 61.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:29<00:00, 119.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3680233134292934\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 117.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.37387650998102295\n",
      "\n",
      "\n",
      "Epoch: 4 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:07<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:32<00:00, 108.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3595370303545646\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 117.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3645341773000028\n",
      "\n",
      "\n",
      "Epoch: 5 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:05<00:00, 54.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:27<00:00, 130.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.35521735013819394\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 148.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3608252906212301\n",
      "\n",
      "\n",
      "Epoch: 6 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:59<00:00, 60.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:24<00:00, 145.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.35039952977835176\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 151.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3550633428750014\n",
      "\n",
      "\n",
      "Epoch: 7 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:55<00:00, 64.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:26<00:00, 134.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3472319741263137\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 130.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3518691433574816\n",
      "\n",
      "\n",
      "Epoch: 8 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:00<00:00, 59.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:29<00:00, 121.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3443948666249103\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 145.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.348893245324643\n",
      "\n",
      "\n",
      "Epoch: 9 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:56<00:00, 62.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:23<00:00, 154.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3423624849456634\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:02<00:00, 155.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.34669999082130615\n",
      "\n",
      "\n",
      "Epoch: 10 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:54<00:00, 64.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:25<00:00, 138.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3406286493085958\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 128.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.3450131125070832\n",
      "\n",
      "\n",
      "Epoch: 11 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:05<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:32<00:00, 109.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.3387381474422398\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 110.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.343080557920415\n",
      "\n",
      "\n",
      "Epoch: 12 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:10<00:00, 50.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:31<00:00, 113.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.33753593888320915\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 112.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.34175499863546305\n",
      "\n",
      "\n",
      "Epoch: 13 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:06<00:00, 53.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3563/3563 [00:30<00:00, 116.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Train Set:  0.33611121611032396\n",
      "\n",
      "Test with test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 396/396 [00:03<00:00, 115.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Mean loss Test Set:  0.34086028512830685\n",
      "\n",
      "\n",
      "Epoch: 14 of 200\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3563/3563 [01:07<00:00, 53.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████                                                              | 731/3563 [00:06<00:25, 111.18it/s]"
     ]
    }
   ],
   "source": [
    "training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if models['smallest'][7] is True:\n",
    "\n",
    "    utils_bsc.print_results_training(train_loss=training_results_transformers['smallest'][4], test_loss=training_results_transformers['smallest'][5], test_loss_baseline=baseline_loss, baseline_label='Vanilla transformer Test Loss', title=\"Training results \" + 'smallest' + \" Transformer (\" + str(models['smallest'][0]) + \" encoder layers, \" + str(models['smallest'][1]) + \" decoder layer, \" + str(models['smallest'][2]) + \" heads. \" + models['smallest'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models['smallest'][7] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train a bigger transformer model with SGD with momentum as optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#models['bigger'] = [10, 5, 9, 4096, 'SGD', 0.001, 0.9, True, 30, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if models['bigger'][7] is True:\n",
    "#     baseline_loss = [np.mean(i) for i in training_results_transformers['vanilla'][5]]\n",
    "#     utils_bsc.print_results_training(train_loss=training_results_transformers['bigger'][4], test_loss=training_results_transformers['bigger'][5], test_loss_baseline=baseline_loss, baseline_label='Vanilla transformer Test Loss', title=\"Training results \" + 'bigger' + \" Transformer (\" + str(models['bigger'][0]) + \" encoder layers, \" + str(models['bigger'][1]) + \" decoder layer, \" + str(models['bigger'][2]) + \" heads. \" + models['bigger'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models['bigger'][7] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try with different sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models['seq_15'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 15, 16]\n",
    "# models['seq_60'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 60, 16]\n",
    "# models['seq_2'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 2, 16]\n",
    "# models['seq_20'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 20, 16]\n",
    "# models['seq_10'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 10, 16]\n",
    "# models['seq_120'] = [6, 1, 6, 2048, 'SGD', 0.001, 0.9, True, 120, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_results_transformers = utils_bsc.define_train_transformers(models, device, dataset_norm, training_results_transformers, saved_results, colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, bias_init: float):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(self.lstm.hidden_size, output_size)\n",
    "\n",
    "        # Deactivate forget gate to be in line with the original definition.\n",
    "        def _reset_forget_gate_hook(_gradients: torch.Tensor) -> torch.Tensor:\n",
    "            _gradients[_gradients.shape[0] // 4:_gradients.shape[0] // 2].fill_(0.0)\n",
    "            return _gradients\n",
    "\n",
    "        for name, parameter in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                parameter.data[(parameter.shape[0] // 4):(parameter.shape[0] // 2)].fill_(bias_init)\n",
    "                parameter.register_hook(_reset_forget_gate_hook)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.lstm(x)[0][:, -1, :]\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_lstm(model, optimizer, criterion, train_loader, test_loader, n_epochs, train_loss=None,\n",
    "                         test_loss=None):\n",
    "    if train_loss is not None:\n",
    "        epoch_loss_train = train_loss\n",
    "        best_train_loss = min([np.mean(i) for i in train_loss])\n",
    "        best_epoch = np.where(min([np.mean(i) for i in test_loss]))\n",
    "    else:\n",
    "        epoch_loss_train = []\n",
    "        best_train_loss = 9999999999\n",
    "        best_epoch = 0\n",
    "\n",
    "    if test_loss is not None:\n",
    "        epoch_loss_test = test_loss\n",
    "        best_test_loss = min([np.mean(i) for i in test_loss])\n",
    "        best_epoch = np.where(min([np.mean(i) for i in train_loss]))\n",
    "    else:\n",
    "        epoch_loss_test = []\n",
    "        best_test_loss = 99999999999\n",
    "        best_epoch = 0\n",
    "\n",
    "    best_model = model\n",
    "    starting_epoch = len(epoch_loss_test)\n",
    "\n",
    "    for e in range(1, n_epochs + 1):\n",
    "\n",
    "        print(f'Epoch: {e + starting_epoch} of {n_epochs}')\n",
    "        print('Training...')\n",
    "        model.train()\n",
    "\n",
    "        for i in tqdm(train_loader):\n",
    "            input = i[0]\n",
    "            target = i[1]\n",
    "\n",
    "            net_out = model.forward(input)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(net_out, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "\n",
    "            # Optimization\n",
    "            optimizer.step()\n",
    "\n",
    "        print('\\nTest with training set')\n",
    "        losses_train = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(train_loader):\n",
    "                input = i[0]\n",
    "                target = i[2]\n",
    "\n",
    "                net_out = model.forward(input)\n",
    "\n",
    "                # Compute loss\n",
    "                losses_train.append(float(criterion(net_out, target).item()))\n",
    "\n",
    "        print('\\nCurrent Mean loss Train Set: ', np.mean(losses_train))\n",
    "        epoch_loss_train.append(losses_train)\n",
    "\n",
    "        print('\\nTest with test set')\n",
    "        losses_test = []\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(test_loader):\n",
    "                input = i[0]\n",
    "                target = i[1]\n",
    "\n",
    "                net_out = model.forward(input)\n",
    "\n",
    "                # Compute loss\n",
    "                losses_test.append(float(criterion(net_out, target).item()))\n",
    "\n",
    "        print('\\nCurrent Mean loss Test Set: ', np.mean(losses_test))\n",
    "        epoch_loss_test.append(losses_test)\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        if np.mean(losses_test) < best_test_loss:\n",
    "            best_test_loss = np.mean(losses_test)\n",
    "            best_train_loss = np.mean(losses_train)\n",
    "            best_model = model\n",
    "            best_epoch = e\n",
    "\n",
    "    return (best_model, best_train_loss, best_test_loss, best_epoch), epoch_loss_train, epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_train_lstm(models, device, dataset, training_results_transformers, path_save, colab):\n",
    "    for i in models:\n",
    "        if models[i][7] is True:\n",
    "\n",
    "            loader_train, loader_test = utils_bsc.create_sequece_dataloaders(dataset=dataset, seq_length=models[i][8],\n",
    "                                                                   batch_size=models[i][9], device=device)\n",
    "\n",
    "            target_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = LSTM(input_size=18, hidden_size= 32, output_size=18, bias_init=0.0).to(target_device)\n",
    "\n",
    "            print(f'Model: {type(model).__name__} - {i}')\n",
    "            print(f'{utils_bsc.count_parameters(model)} trainable parameters.')\n",
    "\n",
    "            n_epochs = 200\n",
    "            learning_rate = 0.01\n",
    "\n",
    "            if models[i][4] == 'SGD':\n",
    "\n",
    "                if models[i][6] is not None:\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr=models[i][5], momentum=models[i][6])\n",
    "                else:\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr=models[i][5])\n",
    "            elif models[i][4] == 'ADAM':\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=models[i][5])\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            start_time = datetime.now()\n",
    "\n",
    "            best_results, train_losses, test_losses = training_lstm(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=loader_train,\n",
    "                test_loader=loader_test,\n",
    "                n_epochs=n_epochs)\n",
    "\n",
    "            Transformer_trained_Model = best_results[0]\n",
    "            best_train_loss = best_results[1]\n",
    "            best_test_loss = best_results[2]\n",
    "            best_epoch_number = best_results[3]\n",
    "\n",
    "            end_time = datetime.now()\n",
    "            time_diff = (end_time - start_time)\n",
    "            execution_time = time_diff.total_seconds()\n",
    "\n",
    "            print(f'Best test loss at epoch {best_epoch_number}')\n",
    "            print(f'Train Loss: {best_train_loss}')\n",
    "            print(f'Test Loss: {best_test_loss}')\n",
    "            print(f'\\nTraining time for {n_epochs} epochs: {execution_time} seconds')\n",
    "\n",
    "            print(f'Training time: {execution_time} seconds')\n",
    "\n",
    "            training_results_transformers[i] = [Transformer_trained_Model, best_train_loss, best_test_loss,\n",
    "                                                best_epoch_number, train_losses, test_losses, execution_time]\n",
    "\n",
    "            # save to npy file\n",
    "            np.save(path_save + '/Transformer_' + i + '_train.npy', train_losses)\n",
    "            np.save(path_save + '/Transformer_' + i + '_test.npy', test_losses)\n",
    "            torch.save(Transformer_trained_Model, path_save + '/Transformer_' + models[i][8] + '.pt')\n",
    "\n",
    "            if colab is True:\n",
    "                from google.colab import files\n",
    "\n",
    "                files.download(path_save + '/Transformer_' + i + '_train.npy')\n",
    "                files.download(path_save + '/Transformer_' + i + '_test.npy')\n",
    "                files.download(path_save + '/Transformer_' + i + '.pt')\n",
    "\n",
    "    return training_results_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models = {}\n",
    "# training_results_lstm = {}\n",
    "\n",
    "# models['lstm'] = [1, 1, 1, 512, 'SGD', 0.001, 0.9, True, 30, 16]\n",
    "\n",
    "# training_results_lstm = define_train_lstm(models, device, dataset_norm, training_results_lstm, saved_results, colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "bsc_arbeit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}